import os
import sys
import torch
import cv2
import numpy as np
from pathlib import Path
from huggingface_hub import hf_hub_download
import logging
from typing import List, Dict, Any
import tempfile
import shutil

logger = logging.getLogger(__name__)

class YOLOv7Model:
    """YOLOv7 Í∏∞Î∞ò ÌîÑÎ†àÏä§ Íµ¨Î©ç Í≤∞Ìï® ÌÉêÏßÄ Î™®Îç∏"""
    
    def __init__(self):
        self.model = None
        self.device = None
        self.img_size = 640
        self.conf_thres = 0.25
        self.iou_thres = 0.45
        self.model_loaded = False
        
        # Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ïÏùò
        self.category_names = {
            0: 'AX1', 1: 'BY1', 2: 'CY1', 3: 'DY1', 
            4: 'DY2', 5: 'DY3', 6: 'DY4'
        }
        
        # ÏµúÏ†ÅÌôîÎêú Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í (Ïû¨ÌòÑÏú® Í∞úÏÑ† Î≤ÑÏ†Ñ)
        self.adaptive_thresholds = {
            0: 0.15,  # AX1: 15%
            1: 0.50,  # BY1: 50%
            2: 0.20,  # CY1: 20%
            3: 0.40,  # DY1: 40%
            4: 0.45,  # DY2: 45%
            5: 0.25,  # DY3: 25%
            6: 0.35   # DY4: 35%
        }
        
        # YOLOv7 Î†àÌè¨ÏßÄÌÜ†Î¶¨ Í≤ΩÎ°ú
        self.yolov7_path = None
        self.yolov7_loaded = False
    
    def _setup_yolov7_repo(self):
        """YOLOv7 Î†àÌè¨ÏßÄÌÜ†Î¶¨ ÏÑ§Ï†ï"""
        try:
            # # ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú yolov7 Ìè¥Îçî Ï∞æÍ∏∞
            # current_dir = os.getcwd()
            # yolov7_path = os.path.join(current_dir, 'yolov7')

            # Ïù¥ ÌååÏùºÏù¥ ÏúÑÏπòÌïú ÎîîÎ†âÌÜ†Î¶¨ Í∏∞Ï§Ä Ï†àÎåÄÍ≤ΩÎ°ú ÏÑ§Ï†ï
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) 
            yolov7_path = os.path.join(base_dir, 'yolov7')
            
            if not os.path.exists(yolov7_path):
                logger.error(f"YOLOv7 Î†àÌè¨ÏßÄÌÜ†Î¶¨Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {yolov7_path}")
                logger.info("Îã§Ïùå Î™ÖÎ†πÏñ¥Î°ú YOLOv7Î•º ÌÅ¥Î°†ÌïòÏÑ∏Ïöî: git clone https://github.com/WongKinYiu/yolov7.git")
                return False
            
            # # YOLOv7 Í≤ΩÎ°úÎ•º Python pathÏóê Ï∂îÍ∞Ä
            # if yolov7_path not in sys.path:
            #     sys.path.insert(0, yolov7_path)
            #     logger.info(f"YOLOv7 Í≤ΩÎ°úÎ•º sys.path Îß® ÏïûÏóê Ï∂îÍ∞Ä: {yolov7_path}")
            
            sys.path.insert(0, yolov7_path)
            logger.info(f"YOLOv7 Í≤ΩÎ°úÎ•º sys.path Îß® ÏïûÏóê Ï∂îÍ∞Ä: {yolov7_path}")
            
            self.yolov7_path = yolov7_path
            logger.info(f"YOLOv7 Í≤ΩÎ°ú ÏÑ§Ï†ï ÏôÑÎ£å: {yolov7_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"YOLOv7 Î†àÌè¨ÏßÄÌÜ†Î¶¨ ÏÑ§Ï†ï Ïã§Ìå®: {e}")
            return False
    
    def _download_model_from_huggingface(self):
        """ÌóàÍπÖÌéòÏù¥Ïä§ÏóêÏÑú Î™®Îç∏ Îã§Ïö¥Î°úÎìú"""
        try:
            logger.info("ÌóàÍπÖÌéòÏù¥Ïä§ÏóêÏÑú Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë...")
            
            # Î™®Îç∏ ÌååÏùº Îã§Ïö¥Î°úÎìú
            model_path = hf_hub_download(
                repo_id="23smartfactory/press-defect-detection-model",
                filename="press_hole_yolov7_best.pt",
                cache_dir="./model_cache"  # Î°úÏª¨ Ï∫êÏãú ÎîîÎ†âÌÜ†Î¶¨
            )
            
            logger.info(f"Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å: {model_path}")
            return model_path
            
        except Exception as e:
            logger.error(f"Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ïã§Ìå®: {e}")
            raise
    
    def _load_yolov7_dependencies(self):
        """YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî©"""
        try:
            logger.info("YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî© Ï§ë...")
            
            # YOLOv7 Î†àÌè¨ÏßÄÌÜ†Î¶¨ ÏÑ§Ï†ï
            if not self._setup_yolov7_repo():
                return False
            
            # ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            logger.info(f"ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {self.device}")
            
            # YOLOv7 Î™®Îìà import ÏãúÎèÑ
            try:
                from models.experimental import attempt_load
                from utils.general import check_img_size, non_max_suppression, scale_coords
                from utils.datasets import letterbox
                
                # ÌïÑÏöîÌïú Ìï®ÏàòÎì§ÏùÑ Ïù∏Ïä§ÌÑ¥Ïä§ Î≥ÄÏàòÎ°ú Ï†ÄÏû•
                self.attempt_load = attempt_load
                self.non_max_suppression = non_max_suppression
                self.scale_coords = scale_coords
                self.letterbox = letterbox
                self.check_img_size = check_img_size
                
                self.yolov7_loaded = True
                logger.info("YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî© ÏôÑÎ£å")
                return True
                
            except ImportError as e:
                logger.error(f"YOLOv7 Î™®Îìà import Ïã§Ìå®: {e}")
                return False
            
        except Exception as e:
            logger.error(f"YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî© Ïã§Ìå®: {e}")
            return False

    async def load_model(self):
        """Î™®Îç∏ ÎπÑÎèôÍ∏∞ Î°úÎî©"""
        try:
            logger.info("ü§ñ AI Î™®Îç∏ Î°úÎî© ÏãúÏûë...")
            
            # 1. YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî©
            if not self._load_yolov7_dependencies():
                raise Exception("YOLOv7 ÏùòÏ°¥ÏÑ± Î°úÎî© Ïã§Ìå®")
            
            # 2. ÌóàÍπÖÌéòÏù¥Ïä§ÏóêÏÑú Î™®Îç∏ Îã§Ïö¥Î°úÎìú
            model_path = self._download_model_from_huggingface()
            
            # 3. YOLOv7Ïùò attempt_load Ìï®Ïàò ÏÇ¨Ïö©
            logger.info("YOLOv7 Î™®Îç∏ Î°úÎî© Ï§ë...")
            
            # YOLOv7Ïùò attempt_load Ìï®Ïàò ÏÇ¨Ïö©
            self.model = self.attempt_load(model_path, map_location=self.device)
            
            # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï≤¥ÌÅ¨
            self.img_size = self.check_img_size(self.img_size, s=int(self.model.stride.max()))
            
            # Î™®Îç∏ÏùÑ ÌèâÍ∞Ä Î™®ÎìúÎ°ú ÏÑ§Ï†ï
            self.model.eval()
            
            self.model_loaded = True
            logger.info("‚úÖ AI Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå AI Î™®Îç∏ Î°úÎî© Ïã§Ìå®: {e}")
            self.model_loaded = False
            raise
    
    def _preprocess_image(self, image_path: str):
        """Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (YOLOv7 Î∞©Ïãù)"""
        try:
            if not self.yolov7_loaded:
                raise Exception("YOLOv7 ÏùòÏ°¥ÏÑ±Ïù¥ Î°úÎî©ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            
            # Ïù¥ÎØ∏ÏßÄ Î°úÎî©
            img0 = cv2.imread(image_path)
            if img0 is None:
                raise ValueError(f"Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§: {image_path}")
            
            # YOLOv7Ïùò letterbox Ï†ÑÏ≤òÎ¶¨ ÏÇ¨Ïö©
            img = self.letterbox(img0, self.img_size, stride=int(self.model.stride.max()))[0]
            
            # BGR to RGB, HWC to CHW
            img = img[:, :, ::-1].transpose(2, 0, 1)
            img = np.ascontiguousarray(img)
            
            # Ï†ïÍ∑úÌôî Î∞è ÌÖêÏÑú Î≥ÄÌôò
            img = torch.from_numpy(img).to(self.device)
            img = img.float() / 255.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)
            
            return img, img0
            
        except Exception as e:
            logger.error(f"Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
            raise
    
    def _postprocess_detections(self, pred, img, img0):
        """ÌÉêÏßÄ Í≤∞Í≥º ÌõÑÏ≤òÎ¶¨ (YOLOv7 Î∞©Ïãù)"""
        try:
            if not self.yolov7_loaded:
                raise Exception("YOLOv7 ÏùòÏ°¥ÏÑ±Ïù¥ Î°úÎî©ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            
            # NMS Ï†ÅÏö©
            pred = self.non_max_suppression(pred, self.conf_thres, self.iou_thres, classes=None, agnostic=False)
            
            results = []
            
            for i, det in enumerate(pred):  # detections per image
                if len(det):
                    # Ï¢åÌëúÎ•º ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î°ú Î≥ÄÌôò
                    det[:, :4] = self.scale_coords(img.shape[2:], det[:, :4], img0.shape).round()
                    
                    # Í≤∞Í≥º Ï†ÄÏû•
                    for *xyxy, conf, cls in reversed(det):
                        category_id = int(cls)
                        confidence = float(conf)
                        x1, y1, x2, y2 = map(int, xyxy)
                        
                        results.append({
                            'category_id': category_id,
                            'category_name': self.category_names.get(category_id, f'unknown_{category_id}'),
                            'confidence': confidence,
                            'bbox': [x1, y1, x2, y2],
                            'bbox_center': [(x1+x2)/2, (y1+y2)/2]
                        })
            
            return results
            
        except Exception as e:
            logger.error(f"ÌõÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
            return []
    
    def detect_holes(self, image_path: str) -> List[Dict[str, Any]]:
        """Îã®Ïùº Ïù¥ÎØ∏ÏßÄÏóêÏÑú Íµ¨Î©ç ÌÉêÏßÄ"""
        if not self.model_loaded or self.model is None:
            raise Exception("Î™®Îç∏Ïù¥ Î°úÎî©ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
        
        try:
            # Ï†ÑÏ≤òÎ¶¨
            img, img0 = self._preprocess_image(image_path)
            
            # Ï∂îÎ°†
            with torch.no_grad():
                pred = self.model(img, augment=False)[0]
            
            # ÌõÑÏ≤òÎ¶¨
            detections = self._postprocess_detections(pred, img, img0)
            
            logger.info(f"ÌÉêÏßÄ Í≤∞Í≥º: {len(detections)}Í∞ú Íµ¨Î©ç Î∞úÍ≤¨")
            return detections
            
        except Exception as e:
            logger.error(f"Íµ¨Î©ç ÌÉêÏßÄ Ïã§Ìå®: {e}")
            raise
    
    def apply_adaptive_thresholds(self, detections_by_image: Dict) -> Dict:
        """Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞íÏùÑ Ï†ÅÏö©Ìïú ÌíàÏßà Í≤ÄÏÇ¨"""
        try:
            total_images = len(detections_by_image)
            if total_images == 0:
                return {'is_complete': False, 'error': 'Ï≤òÎ¶¨Îêú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏäµÎãàÎã§.'}
            
            # Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ìà¨Ìëú Ïàò Í≥ÑÏÇ∞
            category_vote_count = {cat_id: 0 for cat_id in range(7)}
            
            for image_key, detections in detections_by_image.items():
                detected_categories = set()
                for det in detections:
                    if det['confidence'] >= 0.5:  # ÏµúÏÜå Ïã†Î¢∞ÎèÑ
                        detected_categories.add(det['category_id'])
                
                for cat_id in detected_categories:
                    category_vote_count[cat_id] += 1
            
            # Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö©
            existing_categories = set()
            missing_categories = []
            category_results = {}
            
            for cat_id in range(7):
                threshold_ratio = self.adaptive_thresholds[cat_id]
                required_votes = max(1, int(total_images * threshold_ratio))
                actual_votes = category_vote_count[cat_id]
                vote_ratio = actual_votes / total_images
                
                is_existing = actual_votes >= required_votes
                
                if is_existing:
                    existing_categories.add(cat_id)
                else:
                    missing_categories.append(cat_id)
                
                category_results[cat_id] = {
                    'category_name': self.category_names[cat_id],
                    'threshold_ratio': threshold_ratio,
                    'required_votes': required_votes,
                    'actual_votes': actual_votes,
                    'vote_ratio': vote_ratio,
                    'is_existing': is_existing
                }
            
            # ÏµúÏ¢Ö ÌåêÏ†ï
            is_complete = len(existing_categories) == 7
            quality_status = "Ï†ïÏÉÅÌíà" if is_complete else "Í≤∞Ìï®Ìíà"
            
            return {
                'is_complete': is_complete,
                'quality_status': quality_status,
                'existing_categories': sorted(list(existing_categories)),
                'missing_categories': sorted(missing_categories),
                'missing_category_names': [self.category_names[cat_id] for cat_id in missing_categories],
                'category_results': category_results,
                'processed_images': total_images
            }
            
        except Exception as e:
            logger.error(f"Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö© Ïã§Ìå®: {e}")
            return {'is_complete': False, 'error': str(e)}
    
    def get_model_info(self) -> Dict[str, Any]:
        """Î™®Îç∏ Ï†ïÎ≥¥ Î∞òÌôò"""
        return {
            'model_loaded': self.model_loaded,
            'yolov7_loaded': self.yolov7_loaded,
            'yolov7_path': self.yolov7_path,
            'device': str(self.device) if self.device else None,
            'img_size': self.img_size,
            'conf_thres': self.conf_thres,
            'iou_thres': self.iou_thres,
            'categories': self.category_names,
            'adaptive_thresholds': {
                self.category_names[cat_id]: f"{threshold*100:.0f}%" 
                for cat_id, threshold in self.adaptive_thresholds.items()
            }
        }